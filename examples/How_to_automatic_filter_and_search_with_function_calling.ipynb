{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74629e59",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Knowledge-base-chat-with-automatic-data-filtering-use-function-calling\" data-toc-modified-id=\"Knowledge-base-chat-with-automatic-data-filtering-use-function-calling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Knowledge base chat with automatic data filtering use function calling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Key-Features:\" data-toc-modified-id=\"Key-Features:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Key Features:</a></span></li></ul></li><li><span><a href=\"#Prep-Data\" data-toc-modified-id=\"Prep-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prep Data</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Data-preprocess-utilities\" data-toc-modified-id=\"Data-preprocess-utilities-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data preprocess utilities</a></span></li><li><span><a href=\"#Load-and-split-data\" data-toc-modified-id=\"Load-and-split-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Load and split data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split-Dataframe-with-Metadata\" data-toc-modified-id=\"Split-Dataframe-with-Metadata-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Split Dataframe with Metadata</a></span></li><li><span><a href=\"#Embed-and-save-to-local-dir\" data-toc-modified-id=\"Embed-and-save-to-local-dir-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Embed and save to local dir</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quick-cost-estimation\" data-toc-modified-id=\"Quick-cost-estimation-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Quick cost estimation</a></span></li><li><span><a href=\"#Embed-and-save\" data-toc-modified-id=\"Embed-and-save-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Embed and save</a></span></li></ul></li></ul></li><li><span><a href=\"#Retrieval-Augmented-Generation-with-data-filter-(via-function-calling)\" data-toc-modified-id=\"Retrieval-Augmented-Generation-with-data-filter-(via-function-calling)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Retrieval Augmented Generation with data filter (via function calling)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Helper-function-for-semantic-search-&amp;-filtering\" data-toc-modified-id=\"Helper-function-for-semantic-search-&amp;-filtering-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Helper function for semantic search &amp; filtering</a></span></li><li><span><a href=\"#Function-calling-ultilities-and-schema\" data-toc-modified-id=\"Function-calling-ultilities-and-schema-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Function calling ultilities and schema</a></span></li><li><span><a href=\"#Chat-with-automatically-filtered,-more-relevant-data.\" data-toc-modified-id=\"Chat-with-automatically-filtered,-more-relevant-data.-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Chat with automatically filtered, more relevant data.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chat-with-dataset\" data-toc-modified-id=\"Chat-with-dataset-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Chat with dataset</a></span></li><li><span><a href=\"#Check-the-context-dataframe-this-answer-is-based-on\" data-toc-modified-id=\"Check-the-context-dataframe-this-answer-is-based-on-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Check the context dataframe this answer is based on</a></span></li></ul></li><li><span><a href=\"#Another-Example\" data-toc-modified-id=\"Another-Example-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Another Example</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b969b2",
   "metadata": {},
   "source": [
    "# Knowledge base chat with automatic data filtering use function calling\n",
    "---\n",
    "\n",
    "This notebook illustrates a workflow tailored for knowledge-based chat interactions that utilize automatic data filtering through function calls. \n",
    "\n",
    "It's common to target specific data subsets; for example, in an Earnings Call Transcript dataset (with multiple companies and many calls across whole year), one might only interested in Nvidia's Q3 performance. However, a simple semantic search, even when enriched with date augmentation, often isn't comprehensive enough. This notebook provides a method for precise question-answering using contextually filtered data.\n",
    "\n",
    "\n",
    "Here, Im using a sliced Earnings Call Transcript files from 2020, but this idea can be easily applied to other datasets. \n",
    "\n",
    "## Key Features:\n",
    "1. **Text Splitting and Embeding**: Breaks down large transcripts into manageable chunks for better semantic search, optionally add contextual metadata. \n",
    "    - see **split_df_with_metadata** for more details\n",
    "    \n",
    "\n",
    "2. **Question Answering With Filtered Data**: Retrieval Augmented Generation with pre-filtered & more relevant data. Using function callings to adapt user questions into actionable queries to filter data, then doing retreivial and question answering. \n",
    "\n",
    "    - For instance, asking question like \"whats Microsoft says about Azure in Q3 that year?\" triggers call like `{'query': 'Azure in Q3', 'company_names': ['Microsoft Corporation (MSFT)'], 'start_date': '2020-07-01', 'end_date': '2020-09-30'}` to first filter dataset for more relevant ones. Before starting the RAG and chat process. \n",
    "    - see **get_answer_with_filtered_df** and **chat_completion_with_function_execution** for more details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cb96d",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818906b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install scipy\n",
    "!pip install tenacity\n",
    "!pip install langchain  \n",
    "!pip install tiktoken\n",
    "!pip install pandas\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b026ba1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:33:42.865977Z",
     "start_time": "2023-10-03T01:33:42.849595Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Optional\n",
    "from scipy import spatial\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import json\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "GPT_MODEL = \"gpt-4-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "LOCAL_FILENAME = \"ECT_selected.feather\"\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "# openai.api_key = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a8675",
   "metadata": {},
   "source": [
    "# Data preprocess utilities\n",
    "Breaks down large transcripts into manageable chunks for better semantic search, optionally add contextual metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9ffc2185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:47.071376Z",
     "start_time": "2023-10-03T01:22:47.063552Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tiktoken_len(text):\n",
    "    \"\"\"Calculate the token length for a given text using tiktoken.\"\"\"\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "\n",
    "def split_text_using_threshold(row, target_col_name, splitter):\n",
    "    \"\"\"\n",
    "    Split a text using the recursive splitter based on token count.\n",
    "    \"\"\"\n",
    "    if row[\"token_count\"] > splitter._chunk_size:\n",
    "        return splitter.split_text(row[target_col_name])\n",
    "    return [row[target_col_name]]\n",
    "\n",
    "\n",
    "def add_context_to_text(row, target_col_name, context_col_names):\n",
    "    \"\"\"\n",
    "    Add context to a chunk of text if it's not the first chunk.\n",
    "    Constructs a dictionary-like context string using multiple columns.\n",
    "    \"\"\"\n",
    "    if row[\"chunk_id\"] == 0:\n",
    "        return row[target_col_name]\n",
    "\n",
    "    context_strings = []\n",
    "    for col in context_col_names:\n",
    "        value = row[col][\n",
    "            :300\n",
    "        ]  # Taking only the first 300 characters for brevity and not break max_token\n",
    "        context_strings.append(f\"{col}: {value}\")\n",
    "\n",
    "    context = \"; \".join(context_strings)\n",
    "    return f\"context:{context};\\n{row[target_col_name]}\"\n",
    "\n",
    "\n",
    "def split_df_with_metadata(\n",
    "    df,\n",
    "    target_col_name,\n",
    "    max_token_threshold=2500,\n",
    "    add_context_for_chunks=False,\n",
    "    context_col_names=[],\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursively splits texts by separators from a DataFrame while preserving metadata.\n",
    "    optionally add additional context based on metadata.\n",
    "    \"\"\"\n",
    "    # Initialize token counts if not already present\n",
    "    if \"token_count\" not in df.columns:\n",
    "        df[\"token_count\"] = df[target_col_name].apply(get_tiktoken_len)\n",
    "\n",
    "    # Initialize the recursive splitter\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=separators,\n",
    "        chunk_size=max_token_threshold,\n",
    "        chunk_overlap=100,\n",
    "        length_function=get_tiktoken_len,\n",
    "    )\n",
    "\n",
    "    # Use helper function for splitting\n",
    "    df_expanded = df.copy()\n",
    "    df_expanded[\"chunks\"] = df_expanded.apply(\n",
    "        lambda row: split_text_using_threshold(row, target_col_name, splitter), axis=1\n",
    "    )\n",
    "\n",
    "    # Expand the dataframe based on the split chunks\n",
    "    df_expanded = df_expanded.explode(\"chunks\")\n",
    "    df_expanded[target_col_name] = df_expanded[\"chunks\"]\n",
    "    df_expanded[\"chunk_id\"] = df_expanded.groupby(level=0).cumcount()\n",
    "    df_expanded.drop(columns=[\"chunks\"], inplace=True)\n",
    "\n",
    "    # Add context if required using helper function\n",
    "    if add_context_for_chunks:\n",
    "        df_expanded[target_col_name] = df_expanded.apply(\n",
    "            lambda row: add_context_to_text(row, target_col_name, context_col_names),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    # Update token count post processing\n",
    "    df_expanded[\"token_count\"] = df_expanded[target_col_name].apply(get_tiktoken_len)\n",
    "\n",
    "    # Remove empty rows\n",
    "    df_expanded = df_expanded[df_expanded[target_col_name] != \"\"]\n",
    "    df_expanded.dropna(subset=[target_col_name], inplace=True)\n",
    "\n",
    "    return df_expanded\n",
    "\n",
    "\n",
    "# Embedding helper functions\n",
    "async def aembedding_query(text, model=EMBEDDING_MODEL):\n",
    "    response = await openai.Embedding.acreate(input=text, model=model)\n",
    "    return response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "def embedding_query(text, model=EMBEDDING_MODEL):\n",
    "    response = openai.Embedding.create(input=text, model=model)\n",
    "    return response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "async def embedding_docs(texts, model=EMBEDDING_MODEL):\n",
    "    responses = await openai.Embedding.acreate(input=texts, model=model)\n",
    "    embedding_results = [r[\"embedding\"] for r in responses[\"data\"]]\n",
    "    return embedding_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409c61d",
   "metadata": {},
   "source": [
    "# Load and split data\n",
    "\n",
    "Use a sliced 2020's ECT data (only include Nvidia and Microsoft) for quick demo. \n",
    "\n",
    "Raw Data from Kaggle: https://www.kaggle.com/datasets/notis23/earnings-call-us-2020-sentiment-analysis-covid19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fe9a2d4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:48.951487Z",
     "start_time": "2023-10-03T01:22:47.828118Z"
    }
   },
   "outputs": [],
   "source": [
    "ect_data_url = \"https://drive.google.com/uc?export=download&id=1vgpNe8ekkCqVqdVdXpoU4QsAvCuKfUp6\"\n",
    "data_df = pd.read_csv(ect_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4e56a8b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:48.967492Z",
     "start_time": "2023-10-03T01:22:48.957488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>article</th>\n",
       "      <th>company</th>\n",
       "      <th>call_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA Corporation (NVDA) CEO Jensen Huang on ...</td>\n",
       "      <td>NVIDIA Corporation (NASDAQ:NVDA) Q4 2020 Earni...</td>\n",
       "      <td>NVIDIA Corporation (NVDA)</td>\n",
       "      <td>2020-02-13 21:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation (MSFT) CEO Satya Nadella...</td>\n",
       "      <td>Microsoft Corporation (NASDAQ:MSFT) Q2 2020 Ea...</td>\n",
       "      <td>Microsoft Corporation (MSFT)</td>\n",
       "      <td>2020-01-29 21:38:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0  NVIDIA Corporation (NVDA) CEO Jensen Huang on ...   \n",
       "1  Microsoft Corporation (MSFT) CEO Satya Nadella...   \n",
       "\n",
       "                                             article  \\\n",
       "0  NVIDIA Corporation (NASDAQ:NVDA) Q4 2020 Earni...   \n",
       "1  Microsoft Corporation (NASDAQ:MSFT) Q2 2020 Ea...   \n",
       "\n",
       "                        company            call_date  \n",
       "0     NVIDIA Corporation (NVDA)  2020-02-13 21:46:00  \n",
       "1  Microsoft Corporation (MSFT)  2020-01-29 21:38:00  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85917fb6",
   "metadata": {},
   "source": [
    "## Split Dataframe with Metadata\n",
    "The text is divided into smaller chunks, each containing up to 800 tokens. \n",
    "\n",
    "Optional context/metadata can be added to each chunk for clarity of the larger document.\n",
    "(This ensures that every chunk retains a sense of its broader context. For instance, even a segment of an article would be aware of its title and publication date.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6e650a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:49.441693Z",
     "start_time": "2023-10-03T01:22:48.968492Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df = split_df_with_metadata(\n",
    "    data_df,\n",
    "    target_col_name=\"article\",\n",
    "    max_token_threshold=800, # Use 800 token as chunk_size\n",
    "    add_context_for_chunks=True,\n",
    "    context_col_names=[\"company\", \"call_date\"],\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05eff322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:49.457693Z",
     "start_time": "2023-10-03T01:22:49.442694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>article</th>\n",
       "      <th>company</th>\n",
       "      <th>call_date</th>\n",
       "      <th>token_count</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA Corporation (NVDA) CEO Jensen Huang on ...</td>\n",
       "      <td>NVIDIA Corporation (NASDAQ:NVDA) Q4 2020 Earni...</td>\n",
       "      <td>NVIDIA Corporation (NVDA)</td>\n",
       "      <td>2020-02-13 21:46:00</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA Corporation (NVDA) CEO Jensen Huang on ...</td>\n",
       "      <td>context:company: NVIDIA Corporation (NVDA); ca...</td>\n",
       "      <td>NVIDIA Corporation (NVDA)</td>\n",
       "      <td>2020-02-13 21:46:00</td>\n",
       "      <td>797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0  NVIDIA Corporation (NVDA) CEO Jensen Huang on ...   \n",
       "0  NVIDIA Corporation (NVDA) CEO Jensen Huang on ...   \n",
       "\n",
       "                                             article  \\\n",
       "0  NVIDIA Corporation (NASDAQ:NVDA) Q4 2020 Earni...   \n",
       "0  context:company: NVIDIA Corporation (NVDA); ca...   \n",
       "\n",
       "                     company            call_date  token_count  chunk_id  \n",
       "0  NVIDIA Corporation (NVDA)  2020-02-13 21:46:00          774         0  \n",
       "0  NVIDIA Corporation (NVDA)  2020-02-13 21:46:00          797         1  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a88ddc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:49.820315Z",
     "start_time": "2023-10-03T01:22:49.808088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 5), (244, 6))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape, new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bea3a3",
   "metadata": {},
   "source": [
    "## Embed and save to local dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102e043",
   "metadata": {},
   "source": [
    "### Quick cost estimation\n",
    "*Token cost as of Oct, 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "76e4603d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:51.767158Z",
     "start_time": "2023-10-03T01:22:51.760154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embedding cost: 0.02 USD\n"
     ]
    }
   ],
   "source": [
    "COST_PER_TOKEN_IN_USD = 0.0000001   # $0.0001 / 1K\n",
    "embedding_cost = round(new_df.token_count.sum() * COST_PER_TOKEN_IN_USD, 2)\n",
    "print(f\"Total embedding cost: {embedding_cost} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be952d6f",
   "metadata": {},
   "source": [
    "### Embed and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "70641cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:54.565506Z",
     "start_time": "2023-10-03T01:22:52.810466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use async call for quick embedding \n",
    "new_df['embedding'] = await embedding_docs(new_df['article'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "826ac375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:54.597451Z",
     "start_time": "2023-10-03T01:22:54.566506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to local dir for loading later. Use feather format for faster loading.\n",
    "new_df.reset_index().to_feather(LOCAL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3fd42",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation with data filter (via function calling)\n",
    "Retrieval Augmented Generation with pre-filtered & more relevant data. \n",
    "\n",
    "Using function callings to adapt user questions into actionable queries to filter data, then doing retreivial and question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fbc1de",
   "metadata": {},
   "source": [
    "## Helper function for semantic search & filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "805c59d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:22:57.789727Z",
     "start_time": "2023-10-03T01:22:57.778124Z"
    }
   },
   "outputs": [],
   "source": [
    "QA_PROMPT_TEMPLATE = \"\"\"You are an helpful AI assistant for answering questions about Earnings Call Transcript.\n",
    "You are given the following extracted parts of a earling calls and a question as reference. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"I'm not sure.\" Don't try to make up an answer.\n",
    "Answer in a professional manner, and notice that not all the references are relevant, feel free to ignore parts of it. \n",
    "\n",
    "Question: {question}\n",
    "=========\n",
    "Reference:\n",
    "{context}\n",
    "=========\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "def get_relevant_context(\n",
    "    question,\n",
    "    df,\n",
    "    max_context_len=3000,\n",
    "    embed_model=\"text-embedding-ada-002\",\n",
    "    top_k=3,\n",
    "    print_top_relevant_chunks=False,\n",
    "    max_distance=0.26,\n",
    "    column_name_map=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # Default column names\n",
    "    if column_name_map is None:\n",
    "        column_name_map = {\n",
    "            \"embedding\": \"embedding\",\n",
    "            \"token_count\": \"token_count\",\n",
    "            \"text\": \"article\",\n",
    "        }\n",
    "\n",
    "    question_embedding = embedding_query(question, model=embed_model)\n",
    "\n",
    "    # Calculate distances from embeddings\n",
    "    df[\"distances\"] = distances_from_embeddings(\n",
    "        question_embedding,\n",
    "        df[column_name_map[\"embedding\"]].values,\n",
    "        distance_metric=\"cosine\",\n",
    "    )\n",
    "\n",
    "    if print_top_relevant_chunks:\n",
    "        print(df.sort_values(\"distances\", ascending=True).head(3))\n",
    "\n",
    "    context_list = []\n",
    "    current_len = 0\n",
    "    returned_df_idx = None\n",
    "\n",
    "    # Sort df by distance\n",
    "    sorted_df = (\n",
    "        df[df.distances <= max_distance]\n",
    "        .sort_values(\"distances\", ascending=True)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Add context by top_k, break if reach max_len\n",
    "    for i, row in sorted_df.iterrows():\n",
    "        current_len += row[column_name_map[\"token_count\"]]\n",
    "\n",
    "        if current_len > max_context_len or i + 1 > top_k:\n",
    "            break\n",
    "\n",
    "        context_list.append(row[column_name_map[\"text\"]])\n",
    "        returned_df_idx = i\n",
    "\n",
    "    # Check if no context was found\n",
    "    if not context_list:\n",
    "        print(\n",
    "            f\"No context with sufficient relevancy found, please adjust max_distance if you want results \\n(currently threshold: {max_distance}, current nearest dist {round(sorted_df.distances.iloc[0], 2)})) .\"\n",
    "        )\n",
    "        return None, None\n",
    "\n",
    "    return \"\\n\\n##Context:\\n\\n\".join(context_list), sorted_df.head(returned_df_idx + 1)\n",
    "\n",
    "\n",
    "def distances_from_embeddings(\n",
    "    query_embedding: List[float],\n",
    "    embeddings: List[List[float]],\n",
    "    distance_metric=\"cosine\",\n",
    ") -> List[List]:\n",
    "    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\n",
    "    distance_metrics = {\n",
    "        \"cosine\": spatial.distance.cosine,\n",
    "        \"L1\": spatial.distance.cityblock,\n",
    "        \"L2\": spatial.distance.euclidean,\n",
    "        \"Linf\": spatial.distance.chebyshev,\n",
    "    }\n",
    "    distances = [\n",
    "        distance_metrics[distance_metric](query_embedding, embedding)\n",
    "        for embedding in embeddings\n",
    "    ]\n",
    "    return distances\n",
    "\n",
    "\n",
    "def get_filtered_df(\n",
    "    df: pd.DataFrame,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    company_names=None,\n",
    "    company_name_col=\"company\",\n",
    "    date_col=\"call_date\",\n",
    ") -> pd.DataFrame:\n",
    "    if company_names:\n",
    "        if isinstance(company_names, str):\n",
    "            company_names = [company_names]\n",
    "        df = df[df[company_name_col].isin(company_names)]\n",
    "\n",
    "    # Check and handle date filters\n",
    "    if start_date or end_date:\n",
    "        if start_date and end_date and start_date > end_date:\n",
    "            raise ValueError(\"start_date should be earlier than or equal to end_date.\")\n",
    "\n",
    "        date_filter = (df[date_col] >= (start_date or df[date_col].min())) & (\n",
    "            df[date_col] <= (end_date or df[date_col].max())\n",
    "        )\n",
    "        df = df[date_filter]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_answer_with_filtered_df(\n",
    "    query,\n",
    "    company_names=[],\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    max_tokens=500,\n",
    "    df_dir=LOCAL_FILENAME,\n",
    "    max_context_len=3000,\n",
    "    embed_model=\"text-embedding-ada-002\",\n",
    "    top_k=5,\n",
    "    max_distance=0.3,\n",
    "    print_top_relevant_chunks=False,\n",
    "):\n",
    "    # Read saved_df\n",
    "    df = pd.read_feather(df_dir).reset_index(drop=True)\n",
    "\n",
    "    # Get filtered_df based on query and company name\n",
    "    filtered_df = get_filtered_df(\n",
    "        df,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        company_names=company_names,\n",
    "    )\n",
    "    print(\n",
    "        f\"Filtered {len(filtered_df)}  relevant document found given the time frame: {start_date}, {end_date} for company: {company_names}. out of {len(df)} docs.\"\n",
    "    )\n",
    "    if len(filtered_df) == 0:\n",
    "        # mimic the [\"choices\"][0][\"message\"][\"content\"] results\n",
    "        return {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"message\": {\n",
    "                        \"content\": f\"No relevant document found given the time frame: {start_date}, {end_date} for company: {company_names}.\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Get proper context by question.\n",
    "    context_str, context_df = get_relevant_context(\n",
    "        query,\n",
    "        filtered_df,\n",
    "        max_context_len=max_context_len,\n",
    "        embed_model=embed_model,\n",
    "        top_k=top_k,\n",
    "        print_top_relevant_chunks=print_top_relevant_chunks,\n",
    "        max_distance=max_distance,\n",
    "    )\n",
    "\n",
    "    # Get answer based on context\n",
    "    cur_prompt = QA_PROMPT_TEMPLATE.format(context=context_str, question=query)\n",
    "\n",
    "    answer = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": cur_prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return answer, context_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0940499",
   "metadata": {},
   "source": [
    "## Function calling ultilities and schema\n",
    "Function calling parts of the code, \n",
    "\n",
    "please see the **get_answer_with_filtered_df** and **get_filtered_df** for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "540debe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:33:26.271307Z",
     "start_time": "2023-10-03T01:33:26.255924Z"
    }
   },
   "outputs": [],
   "source": [
    "get_answer_with_filtered_df_schema = [\n",
    "    {\n",
    "        \"name\": \"get_answer_with_filtered_df\",\n",
    "        \"description\": \"\"\"Use this function to get answers based for saved Earning transcript calls. You can use parameters like company names, start and end dates to filter out data to make answer more relevant.\n",
    "        \n",
    "        Q1 (First Quarter): January 1 to March 31\n",
    "        Q2 (Second Quarter): April 1 to June 30\n",
    "        Q3 (Third Quarter): July 1 to September 30\n",
    "        Q4 (Fourth Quarter): October 1 to December 31\n",
    "        \"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"\"\"\n",
    "                            Given the conversation and a follow-up question, rephrase the follow-up question to be a standalone question that is not ambiguous. If the given question does not need any additional context, just return the original one as a standalone question, not changing anything. Only change when actually needed.\n",
    "                            \"\"\",\n",
    "                },\n",
    "                \"company_names\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\n",
    "                            \"NVIDIA Corporation (NVDA)\",\n",
    "                            \"Microsoft Corporation (MSFT)\",\n",
    "                        ],\n",
    "                        \"description\": \"\"\"\n",
    "                            Choose between 'NVIDIA Corporation (NVDA)' and 'Microsoft Corporation (MSFT)'. If the user mentions a company like \"nvidia\" or \"that graphic card company with green logo\", help them choose 'NVIDIA Corporation (NVDA)'. If the company is not in the list, respond with \"no I don't have this info\".\n",
    "                            \"\"\",\n",
    "                    },\n",
    "                    \"description\": \"List of company names to filter the dataframe by.\",\n",
    "                },\n",
    "                \"start_date\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"format\": \"date\",\n",
    "                    \"description\": \"\"\"\n",
    "                            Use this when user ask about questions require sepcific date, \n",
    "                            The start date to filter the dataframe by, in the format \"YYYY-MM-DD\". If not mentioned, do not apply this filter.\n",
    "                            \"\"\",\n",
    "                },\n",
    "                \"end_date\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"format\": \"date\",\n",
    "                    \"description\": \"\"\"\n",
    "                            Use this when user ask about questions require sepcific date, \n",
    "                            The end date to filter the dataframe by, in the format \"YYYY-MM-DD\". If not mentioned, do not apply this filter.\n",
    "                            \"\"\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n",
    "\n",
    "\n",
    "# This helper functions for call_helper_function and Conversation class are modified from How_to_call_functions_for_knowledge_retrieval Cookbook example.\n",
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self, detailed=False):\n",
    "        role_to_color = {\n",
    "            \"system\": \"red\",\n",
    "            \"user\": \"green\",\n",
    "            \"assistant\": \"blue\",\n",
    "            \"function\": \"magenta\",\n",
    "        }\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                role_to_color[message[\"role\"]],\n",
    "            )\n",
    "\n",
    "\n",
    "def chat_completion_with_function_execution(messages, functions=[None]):\n",
    "    \"\"\"This function makes a ChatCompletion API call with the option of adding functions\"\"\"\n",
    "    response = chat_completion_request(messages, functions)\n",
    "    print(\"response\", response)\n",
    "    full_message = response.json()[\"choices\"][0]\n",
    "    if full_message[\"finish_reason\"] == \"function_call\":\n",
    "        print(f\"Function generation requested, calling function\")\n",
    "        response, context_df = call_helper_function(messages, full_message)\n",
    "        return response, context_df\n",
    "    else:\n",
    "        print(f\"Function not required, responding to user\")\n",
    "        return response.json(), None\n",
    "\n",
    "\n",
    "def call_helper_function(messages, full_message):\n",
    "    if (\n",
    "        full_message[\"message\"][\"function_call\"][\"name\"]\n",
    "        == \"get_answer_with_filtered_df\"\n",
    "    ):\n",
    "        results = None\n",
    "        try:\n",
    "            parsed_output = json.loads(\n",
    "                full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
    "            )\n",
    "            print(parsed_output)\n",
    "            results, context_df = get_answer_with_filtered_df(**parsed_output)\n",
    "        except Exception as e:\n",
    "            print(f\"Function execution failed\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        try:\n",
    "            return results, context_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            print(e)\n",
    "            raise Exception(\"Function chat request failed\")\n",
    "    else:\n",
    "        raise Exception(\"Function does not exist and cannot be called\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b69b359",
   "metadata": {},
   "source": [
    "## Chat with automatically filtered, more relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0232e32c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:32:44.227736Z",
     "start_time": "2023-10-03T01:32:44.215719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start with a system message\n",
    "ect_system_message = \"\"\"You are a helpful assistant can pull Earning Transcript Calls from Nvidia and Microsoft from year of 2020 to answer user questions. \n",
    "User will be asking questions about the ECT files, and you can use it to find most relevant documents by narrow downn the timeframe and company name, and get the answer based on most relevant documents.\n",
    "Answer in professional and concise manner. \n",
    "\"\"\"\n",
    "ect_conv = Conversation()\n",
    "ect_conv.add_message(\"system\", ect_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d5660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e63b2d8",
   "metadata": {},
   "source": [
    "### Chat with dataset \n",
    "Note that when ask about \"whats Microsoft says about Azure in Q3 that year?\"\n",
    "\n",
    "It first use these infor to do automated data filtering ('company_names': ['Microsoft Corporation (MSFT)'], and 'start_date': '2020-07-01', 'end_date': '2020-09-30') \n",
    "\n",
    "Then, using the filtered data (30 out of 244 records), it trigger the RAG pipeline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e4941d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:23:54.150758Z",
     "start_time": "2023-10-03T01:23:33.505148Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "{'query': 'Microsoft comments on Azure', 'company_names': ['Microsoft Corporation (MSFT)'], 'start_date': '2020-07-01', 'end_date': '2020-09-30'}\n",
      "Filtered 30  relevant document found given the time frame: 2020-07-01, 2020-09-30 for company: ['Microsoft Corporation (MSFT)']. out of 244 docs.\n",
      "\n",
      "\n",
      "Microsoft's comments on Azure highlight their focus on customer success, trust, and a multi-cloud environment. They emphasize their unique position in the market due to their long-standing relationships with enterprises and their investments in security, compliance, accreditation, and connectivity. They also highlight the success of their hybrid model, Azure Arc, which allows customers to connect their infrastructures into one cloud. This has been particularly successful in supporting a multi-cloud environment. They also mention their focus on cyber sovereignty and their global footprint as key differentiators. \n",
      "\n",
      "Microsoft also highlights the success of their Azure Hybrid Benefit program, which has been instrumental in migrating existing Windows Server and SQL Server installed bases to Azure. They also mention several high-profile wins for Azure, including deals with the Department of Defense, AT&T, and Walgreens, and express optimism about future Azure revenue growth from these deals. \n",
      "\n",
      "In terms of future investments, Microsoft is excited about advances in silicon technology and the potential for quantum computing. They are also focusing on understanding the different data schemes used by each industry and providing industry-specific solutions. \n",
      "\n",
      "Finally, Microsoft discusses their efforts to improve internal data center efficiencies, focusing on automating the process of bringing servers from the warehouse to the data center and optimizing their supply chain.\n"
     ]
    }
   ],
   "source": [
    "# Add a user message\n",
    "ect_conv.add_message(\"user\", \"whats Microsoft says about Azure in Q3 that year?\")\n",
    "chat_response, context_df = chat_completion_with_function_execution(\n",
    "    ect_conv.conversation_history, functions=get_answer_with_filtered_df_schema\n",
    ")\n",
    "\n",
    "assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "ect_conv.add_message(\"assistant\", assistant_message)\n",
    "print(f\"\\n\\n{assistant_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb01b22",
   "metadata": {},
   "source": [
    "### Check the context dataframe this answer is based on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6e0978c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:26:30.549222Z",
     "start_time": "2023-10-03T01:26:30.539472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>call_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corporation (MSFT)</td>\n",
       "      <td>2020-09-15 18:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation (MSFT)</td>\n",
       "      <td>2020-09-15 18:54:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        company            call_date\n",
       "0  Microsoft Corporation (MSFT)  2020-09-15 18:54:00\n",
       "1  Microsoft Corporation (MSFT)  2020-09-15 18:54:00"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_df[['company', 'call_date']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cd71f",
   "metadata": {},
   "source": [
    "## Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cba304ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:30:06.684457Z",
     "start_time": "2023-10-03T01:30:06.672702Z"
    }
   },
   "outputs": [],
   "source": [
    "# If not asking follow up question, recommand start a new conversation. \n",
    "ect_conv = Conversation()\n",
    "ect_conv.add_message(\"system\", ect_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "17ea4010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:27:52.986307Z",
     "start_time": "2023-10-03T01:27:27.632020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "{'query': 'Covid impact', 'company_names': ['NVIDIA Corporation (NVDA)'], 'start_date': '2020-01-01', 'end_date': '2020-06-30'}\n",
      "Filtered 53  relevant document found given the time frame: 2020-01-01, 2020-06-30 for company: ['NVIDIA Corporation (NVDA)']. out of 244 docs.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The Covid-19 pandemic has had several impacts on NVIDIA. On the supply chain side, the company's significant presence in the Asia-Pacific region allowed it to be at the forefront of the early stages of the pandemic. This helped them understand the early signals and navigate the challenges, such as the closure of retail channels which impacted their gaming business. However, they were able to quickly shift towards eTail as people began working and learning from home, leading to an increase in demand for gaming for entertainment. \n",
       "\n",
       "In terms of employee health, NVIDIA has been focused on understanding their suppliers and supply chain process, maintaining regular communication to understand the challenges they were facing. They also faced logistical challenges in moving supplies from place to place, but their connections with top suppliers and manufacturers aided them during this process.\n",
       "\n",
       "On the business side, NVIDIA has been using its unique capabilities to fight the virus. Their technology has been used in various scientific endeavors related to Covid-19, such as sequencing the virus, analyzing drug candidates, imaging the virus at molecular resolution, and identifying elevated body temperature with AI cameras. They are also preparing for future outbreaks by developing an end-to-end computational defense system. \n",
       "\n",
       "In terms of financial impact, it's still early to determine the precise impact of the virus on their business. However, they have estimated a possible impact on both their gaming and data center businesses."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a user message\n",
    "ect_conv.add_message(\"user\", \"whats Nvidia says about Covid before July?\")\n",
    "chat_response, context_df = chat_completion_with_function_execution(\n",
    "    ect_conv.conversation_history, functions=get_answer_with_filtered_df_schema\n",
    ")\n",
    "\n",
    "assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "ect_conv.add_message(\"assistant\", assistant_message)\n",
    "display(Markdown(assistant_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "df434608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T01:27:53.002072Z",
     "start_time": "2023-10-03T01:27:52.987308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>call_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA Corporation (NVDA)</td>\n",
       "      <td>2020-06-01 18:23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVIDIA Corporation (NVDA)</td>\n",
       "      <td>2020-05-22 04:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA Corporation (NVDA)</td>\n",
       "      <td>2020-05-22 04:29:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company            call_date\n",
       "0  NVIDIA Corporation (NVDA)  2020-06-01 18:23:00\n",
       "1  NVIDIA Corporation (NVDA)  2020-05-22 04:29:00\n",
       "2  NVIDIA Corporation (NVDA)  2020-05-22 04:29:00"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_df[['company', 'call_date']].head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "465.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
